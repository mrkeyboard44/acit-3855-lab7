version: '3.3'
services:
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181"
    hostname: zookeeper
    volumes:
      - /home/azureuser/zookeeper/data:/opt/zookeeper-3.4.13/data

  kafka:
    image: wurstmeister/kafka
    command: [start-kafka.sh]
    ports:
      - "9092:9092"
    hostname: kafka
    environment:
      KAFKA_CREATE_TOPICS: "events:1:1" # topic:partition:replicas
      KAFKA_ADVERTISED_HOST_NAME: kafka # docker-machine ip
      KAFKA_LISTENERS: INSIDE://:29092,OUTSIDE://:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:29092,OUTSIDE://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LOG_DIR: /kafka/kafka-logs
      KAFKA_BROKER_ID: 1
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - "zookeeper"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /home/azureuser/kafka:/kafka/kafka-logs

  db:
    image: mysql:5.7
    restart: always
    hostname: db
    environment:
      MYSQL_DATABASE: 'events'
      # Password for root access
      MYSQL_ROOT_PASSWORD: 'bcitlabpw2022'
    ports:
      # <Port exposed> : < MySQL Port running inside container>
      - '3306:3306'
    expose:
      # Opens port 3306 on the container
      - '3306'
      # Where our data will be persisted
    volumes:
      - my-db:/var/lib/mysql
  # Names our volume
  receiver:
    build: ../receiver/
    restart: always
    ports:
      - "8080"
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/azureuser/config/receiver:/config
      - /home/azureuser/logs:/logs
    depends_on:
      - kafka
      - storage
    networks:
      - "api.network"

  storage:
    build: ../storage/
    restart: always
    hostname: storage
    ports:
      - "8090"
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/azureuser/config/storage:/config
      - /home/azureuser/logs:/logs
    depends_on:
      - kafka
      - db
    networks:
      - "api.network"
    
  
  processing:
    build: ../processing/
    restart: always
    hostname: processing
    ports:
      - "8100"
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/azureuser/config/processing:/config
      - /home/azureuser/logs:/logs
      - processing-db:/data
    depends_on:
      - kafka
    networks:
      - "api.network"
    

  audit_log:
    build: ../audit_log/
    restart: always
    ports:
      - "8110"
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/azureuser/config/audit_log:/config
      - /home/azureuser/logs:/logs
    depends_on:
      - kafka
    networks:
      - "api.network"

  dashboard:
    build: ../dashboard/
    restart: always
    image: dashboard
    ports:
    - "3000"
    depends_on:
    - processing
    - audit_log
    networks:
      - "api.network"

  health:
    build: ../health/
    restart: always
    image: health
    ports:
    - "8120"
    depends_on:
    - "receiver"
    - "storage"
    - "processing"
    - "audit_log"
    - "dashboard"
    networks:
      - "api.network"

  nginx:
    image: nginx:latest
    # Connects the conf file of the container to the conf file in our folder
    volumes:
    - /home/azureuser/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    # It will start up the nginx only when all api containers have started
    depends_on:
    - "receiver"
    - "storage"
    - "processing"
    - "audit_log"
    - "dashboard"
    - "health"
    # Connects the port 80 of the nginx container to localhost:80 or localhost
    ports:
    - "80:80"
    networks:
    - "api.network"

volumes:
  my-db:
  processing-db:

networks:
  api.network:
